{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MACHINE LEARNING - PROJECT 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from proj1_helpers import *\n",
    "from implementations import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOAD THE TRAINING DATA INTO FEATURE MATRIX, CLASS LABELS and EVENT IDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.74 s, sys: 782 ms, total: 10.5 s\n",
      "Wall time: 11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Load train data and supply path\n",
    "DATA_TRAIN_PATH = '../data/train.csv'\n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FEATURES ENGINEERING & DATA PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#constants definitions\n",
    "PRI_JET_NUM_IDX = 22   \n",
    "PRI_JET_NUM_VALUES = range(4)\n",
    "NUMBER_GROUPS = len(PRI_JET_NUM_VALUES)\n",
    "NBR_FEATURES = 30\n",
    "UNDEFINED_VALUE = -999.\n",
    "print_results = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seperating the data within the four groups\n",
    "jet_groups_indices = [tX[:, PRI_JET_NUM_IDX] == pri_jet_num_value for pri_jet_num_value in PRI_JET_NUM_VALUES]\n",
    "TX_arr = [tX[group_indices] for group_indices in jet_groups_indices]\n",
    "Y_arr, TX_arr = zip(*[(y[group_indices], tX[group_indices]) for group_indices in jet_groups_indices])\n",
    "Y_arr, TX_arr = list(Y_arr), list(TX_arr)\n",
    "\n",
    "#collecting the indices of the undefined features for each group\n",
    "undefined_features = [[], [], [], []]\n",
    "for group_idx in range(NUMBER_GROUPS):\n",
    "    tx = TX_arr[group_idx]\n",
    "    for feature_idx in range(NBR_FEATURES):\n",
    "        feature_column = tx[:, feature_idx]\n",
    "        if np.all(feature_column == UNDEFINED_VALUE):\n",
    "            undefined_features[group_idx].append(feature_idx)\n",
    "\n",
    "#computing the std of the features for each group\n",
    "STDS = [np.std(TX_arr[i], axis = 0) for i in range(NUMBER_GROUPS)]\n",
    "\n",
    "#collecting the indices of the features with no variance (i.e. constant features) within each groups\n",
    "cst_features = [[], [], [], []]\n",
    "for group_idx, elem in enumerate(STDS):\n",
    "    for feature_idx, std in enumerate(elem):\n",
    "        if std == 0. and feature_idx not in undefined_features[group_idx]:\n",
    "            cst_features[group_idx].append(feature_idx)\n",
    "\n",
    "#deleting the features either undefined or with no variance (i.e. constant features) within each groups\n",
    "features_to_keep = ([[x for x in range(NBR_FEATURES) \n",
    "                      if x not in undefined_features[group_idx] and x not in cst_features[group_idx]] \n",
    "                      for group_idx in range(NUMBER_GROUPS)])\n",
    "TX_arr = [TX_arr[group_idx][:, features_to_keep[group_idx]] for group_idx in range(NUMBER_GROUPS)]\n",
    "\n",
    "#standardizing the data\n",
    "for tx in TX_arr:\n",
    "    tx -= np.mean(tx, axis = 0)\n",
    "    tx /= np.std(tx, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features for group 0 :  18\n",
      "Number of features for group 1 :  22\n",
      "Number of features for group 2 :  29\n",
      "Number of features for group 3 :  29\n"
     ]
    }
   ],
   "source": [
    "# Print the remaining number of features for each JET NUMBER\n",
    "for i in PRI_JET_NUM_VALUES:\n",
    "    print(f\"Number of features for group {i} : \", len(features_to_keep[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21]\n",
      "[0, 1, 2, 3, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 29]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29]\n"
     ]
    }
   ],
   "source": [
    "print(features_to_keep[0])\n",
    "print(features_to_keep[1])\n",
    "print(features_to_keep[2])\n",
    "print(features_to_keep[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False ... False  True  True]\n",
      "[ 0.  0.  0. ...  0. -1. -1.]\n"
     ]
    }
   ],
   "source": [
    "print(jet_groups_indices[0])\n",
    "y_p = np.empty(250_000)\n",
    "y_p[jet_groups_indices[0]] = -1\n",
    "print(y_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Data with different models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LEAST SQUARES WITH GRADIENT DESCENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "gammas = [0.01, 0.001, 0.0001, 0.00001]\n",
    "max_iters = 2000\n",
    "\n",
    "# Iterate over some gammas to find the best possible values\n",
    "for gamma in gammas:\n",
    "    print(f\"Gamma = {gamma}\")\n",
    "    \n",
    "    # Iterate over all jet numbers dataframes\n",
    "    for i in range(len(features_to_keep)):\n",
    "        initial_w = np.zeros(len(features_to_keep[i]))\n",
    "        y = Y_arr[i]\n",
    "        tx = TX_arr[i]\n",
    "        weights, loss = least_squares_GD(y, tx, initial_w, max_iters, gamma)\n",
    "        print(f\"    For JET_NB {i}, the obtained loss is {loss:>15}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LEAST SQUARES  WITH STOCHASTIC GRADIENT DESCENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "gammas = [0.1, 0.01, 0.001, 0.0001, 0.00001]\n",
    "max_iters = 1500\n",
    "batch_size = 1\n",
    "\n",
    "# Iterate over some gammas to find the best possible values\n",
    "for gamma in gammas:\n",
    "    print(f\"Gamma = {gamma}\")\n",
    "    \n",
    "    # Iterate over all jet numbers dataframes\n",
    "    for i in range(len(features_to_keep)):\n",
    "        initial_w = np.zeros(len(features_to_keep[i]))\n",
    "        y = Y_arr[i]\n",
    "        tx = TX_arr[i]\n",
    "        weights, loss = least_squares_SGD(y, tx, initial_w, batch_size, max_iters, gamma)\n",
    "        print(f\"    For JET_NB {i}, the obtained loss is {loss:>15}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LEAST SQUARES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(features_to_keep)):\n",
    "    initial_w = np.zeros(len(features_to_keep[i]))\n",
    "    y = Y_arr[i]\n",
    "    tx = TX_arr[i]\n",
    "    weights, loss = least_squares(y, tx)\n",
    "    print(f\"For JET_NB {i}, the obtained loss is {loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RIDGE REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "seed=15\n",
    "degrees=[2,3,4]\n",
    "k_fold=4\n",
    "lambdas = np.logspace(-4, 0, 30)\n",
    "\n",
    "for i in range(len(features_to_keep)):\n",
    "    y = Y_arr[i]\n",
    "    tx = TX_arr[i]\n",
    "    degree, lambda_ = cross_validation_demo_ridge(y, tx, seed, degrees, k_fold, lambdas)\n",
    "    print(f\"For JET_NB {i}, the obtained best degree is {degree} and lambda is {lambda_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "max_iters=10000\n",
    "gamma = 0.05\n",
    "\n",
    "for i in range(len(features_to_keep)):\n",
    "    y = Y_arr[i]\n",
    "    tx = TX_arr[i]\n",
    "    weights, loss = logistic_regression(y, tx, max_iters, gamma)\n",
    "    print(f\"For JET_NB {i}, the obtained loss is {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "max_iters=1000\n",
    "seed=15\n",
    "degrees=[2, 3, 4, 6, 7]\n",
    "k_fold= 4\n",
    "#gammas = [0.1, 0.01, 0.001, 0.0001]\n",
    "gammas = [0.1, 0.01]\n",
    "\n",
    "\n",
    "\n",
    "for i in range(NUMBER_GROUPS):\n",
    "    y = Y_arr[i]\n",
    "    y[y == - 1.0] = 0.0\n",
    "    tx = TX_arr[i]\n",
    "    degree, gamma, rmse_min = cross_validation_demo_logistic(y, tx, max_iters, seed, degrees, k_fold, gammas)\n",
    "    print(f\"For JET_NB {i}, the obtained best degree is {degree} and gamma is {gamma} and loss is {rmse_min}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "max_iters = 1_000\n",
    "seed = 15\n",
    "degrees = [2, 3, 4, 6, 7]\n",
    "k_fold = 4\n",
    "#gammas = [0.1, 0.01, 0.001, 0.0001]\n",
    "gammas = [0.1, 0.01, 0.001]\n",
    "\n",
    "\n",
    "\n",
    "for i in range(NUMBER_GROUPS):\n",
    "    y = Y_arr[i]\n",
    "    y[y == - 1.0] = 0.0\n",
    "    tx = TX_arr[i]\n",
    "    degree, gamma, rmse_min = cross_validation_demo_logistic(y, tx, max_iters, seed, degrees, k_fold, gammas)\n",
    "    print(f\"For JET_NB {i}, the obtained best degree is {degree} and gamma is {gamma} and loss is {rmse_min}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "max_iters = 2_000\n",
    "seed = 15\n",
    "degrees = [1, 2, 3, 4, 5]\n",
    "k_fold = 4\n",
    "#gammas = [0.1, 0.01, 0.001, 0.0001]\n",
    "gammas = [0.1, 0.01, 0.001]\n",
    "\n",
    "\n",
    "\n",
    "for i in range(NUMBER_GROUPS):\n",
    "    y = Y_arr[i]\n",
    "    y[y == - 1.0] = 0.0\n",
    "    tx = TX_arr[i]\n",
    "    degree, gamma, rmse_min = cross_validation_demo_logistic(y, tx, max_iters, seed, degrees, k_fold, gammas)\n",
    "    print(f\"For JET_NB {i}, the obtained best degree is {degree} and gamma is {gamma} and loss is {rmse_min}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REGULARIZED LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "params = []\n",
    "\n",
    "for idx in range(4):\n",
    "    y=np.array(Y_arr[idx])\n",
    "    tX=np.array(TX_arr[idx])\n",
    "    initial_w = np.zeros(len(features_to_keep[idx]))\n",
    "    seed=15\n",
    "    degrees=[2, 4, 7]\n",
    "    k_fold=4\n",
    "    max_iters=200\n",
    "    lambdas = np.logspace(-4, 0, 10)\n",
    "    gammas = [0.01,0.001]\n",
    "    \n",
    "    tuple_ = cross_validation_demo_reg_logistic(y, tX, max_iters, seed, degrees, k_fold, lambdas, gammas)\n",
    "    params.append(tuple_)\n",
    "    print(\"group \",idx, \" tuple : \", tuple_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '../data/test.csv' # TODO: download test data and supply path here \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PRI_JET_NUM_VALUES' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-bd9a0f698c50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mjet_groups_indices_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPRI_JET_NUM_IDX\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mpri_jet_num_value\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpri_jet_num_value\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mPRI_JET_NUM_VALUES\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mTX_test_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgroup_indices\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mgroup_indices\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjet_groups_indices_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#remove not used features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mTX_test_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mTX_test_arr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgroup_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_to_keep\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgroup_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mgroup_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUMBER_GROUPS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'PRI_JET_NUM_VALUES' is not defined"
     ]
    }
   ],
   "source": [
    "jet_groups_indices_test = [tX_test[:, PRI_JET_NUM_IDX] == pri_jet_num_value for pri_jet_num_value in PRI_JET_NUM_VALUES]\n",
    "TX_test_arr = list([tX_test[group_indices] for group_indices in jet_groups_indices_test])\n",
    "\n",
    "#remove not used features\n",
    "TX_test_arr = [TX_test_arr[group_idx][:, features_to_keep[group_idx]] for group_idx in range(NUMBER_GROUPS)]\n",
    "\n",
    "#standardizing the data\n",
    "for tx in TX_test_arr:\n",
    "    tx -= np.mean(tx, axis = 0)\n",
    "    tx /= np.std(tx, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "W_arr = []\n",
    "y_pred = np.empty(len(tX_test))\n",
    "\n",
    "for idx in range(4):\n",
    "    #weight, loss = least_squares_GD(Y_arr[idx], TX_arr[idx], np.zeros(TX_arr[idx].shape[1]), 10000, 0.001)\n",
    "    #weight, loss = least_squares(Y_arr[idx], TX_arr[idx])\n",
    "    #weight, loss = ridge_regression(Y_arr[idx], TX_arr[idx], 0.01)\n",
    "    y_pred[jet_groups_indices_test[idx]] = predict_labels(weight, TX_test_arr[idx])\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: fill in desired name of output file for submission\n",
    "OUTPUT_PATH = '../data/sample-submission.csv'\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = np.array([1, 2, 3])\n",
    "l = np.array([True, False, True, False, False, True])\n",
    "A = np.zeros(6)\n",
    "A[l] = Q\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '../data/test.csv' # TODO: download test data and supply path here \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PREPARE TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jet_groups_indices = [tX_test[:, PRI_JET_NUM_IDX] == pri_jet_num_value for pri_jet_num_value in PRI_JET_NUM_VALUES]\n",
    "TX_test_arr = list([tX_test[group_indices] for group_indices in jet_groups_indices])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: fill in desired name of output file for submission\n",
    "OUTPUT_PATH = '../data/sample-submission.csv'\n",
    "y_pred = predict_labels(weights, tX_test)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST LOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.67 s, sys: 437 ms, total: 8.11 s\n",
      "Wall time: 8.14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Load train data and supply path\n",
    "DATA_TRAIN_PATH = '../data/train.csv'\n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#constants definitions\n",
    "PRI_JET_NUM_IDX = 22   \n",
    "PRI_JET_NUM_VALUES = range(4)\n",
    "NUMBER_GROUPS = len(PRI_JET_NUM_VALUES)\n",
    "NBR_FEATURES = 30\n",
    "UNDEFINED_VALUE = -999.\n",
    "\n",
    "#seperating the data within the four groups\n",
    "jet_groups_indices = [tX[:, PRI_JET_NUM_IDX] == pri_jet_num_value for pri_jet_num_value in PRI_JET_NUM_VALUES]\n",
    "TX_arr = [tX[group_indices] for group_indices in jet_groups_indices]\n",
    "Y_arr, TX_arr = zip(*[(y[group_indices], tX[group_indices]) for group_indices in jet_groups_indices])\n",
    "Y_arr, TX_arr = list(Y_arr), list(TX_arr)\n",
    "\n",
    "#collecting the indices of the undefined features for each group\n",
    "undefined_features = [[], [], [], []]\n",
    "for group_idx in range(NUMBER_GROUPS):\n",
    "    tx = TX_arr[group_idx]\n",
    "    for feature_idx in range(NBR_FEATURES):\n",
    "        feature_column = tx[:, feature_idx]\n",
    "        if np.all(feature_column == UNDEFINED_VALUE):\n",
    "            undefined_features[group_idx].append(feature_idx)\n",
    "\n",
    "#computing the std of the features for each group\n",
    "STDS = [np.std(TX_arr[i], axis = 0) for i in range(NUMBER_GROUPS)]\n",
    "\n",
    "#collecting the indices of the features with no variance (i.e. constant features) within each groups\n",
    "cst_features = [[], [], [], []]\n",
    "for group_idx, elem in enumerate(STDS):\n",
    "    for feature_idx, std in enumerate(elem):\n",
    "        if std == 0. and feature_idx not in undefined_features[group_idx]:\n",
    "            cst_features[group_idx].append(feature_idx)\n",
    "\n",
    "#deleting the features either undefined or with no variance (i.e. constant features) within each groups\n",
    "features_to_keep = ([[x for x in range(NBR_FEATURES) \n",
    "                      if x not in undefined_features[group_idx] and x not in cst_features[group_idx]] \n",
    "                      for group_idx in range(NUMBER_GROUPS)])\n",
    "TX_arr = [TX_arr[group_idx][:, features_to_keep[group_idx]] for group_idx in range(NUMBER_GROUPS)]\n",
    "\n",
    "#standardizing the data\n",
    "for tx in TX_arr:\n",
    "    tx -= np.mean(tx, axis = 0)\n",
    "    tx /= np.std(tx, axis = 0)\n",
    "\n",
    "#loading the test data and creating the groups\n",
    "DATA_TEST_PATH = '../data/test.csv' # TODO: download test data and supply path here \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)\n",
    "jet_groups_indices_test = [tX_test[:, PRI_JET_NUM_IDX] == pri_jet_num_value for pri_jet_num_value in PRI_JET_NUM_VALUES]\n",
    "TX_test_arr = list([tX_test[group_indices] for group_indices in jet_groups_indices_test])\n",
    "\n",
    "#remove unused features\n",
    "TX_test_arr = [TX_test_arr[group_idx][:, features_to_keep[group_idx]] for group_idx in range(NUMBER_GROUPS)]\n",
    "\n",
    "#standardizing the data\n",
    "for tx in TX_test_arr:\n",
    "    tx -= np.mean(tx, axis = 0)\n",
    "    tx /= np.std(tx, axis = 0)\n",
    "    \n",
    "#learning the weights and predicting for each group\n",
    "LAMBDA_IDX = 1\n",
    "DEGREE_IDX = 0\n",
    "W_arr = []\n",
    "y_pred = np.empty(len(tX_test))\n",
    "MAX_ITER = 10_000\n",
    "PARAM_arr = [[1, 0.01], [1, 0.001], [1, 0.01], [1, 0.01]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Current iteration=0, loss=[[69254.41425129]]\n",
      "    Current iteration=1000, loss=[[61095.86229029]]\n",
      "    Current iteration=2000, loss=[[53295.8386255]]\n",
      "    Current iteration=3000, loss=[[45828.27905723]]\n",
      "    Current iteration=4000, loss=[[38667.67179652]]\n",
      "    Current iteration=5000, loss=[[31789.59089485]]\n",
      "    Current iteration=6000, loss=[[25171.04753494]]\n",
      "    Current iteration=7000, loss=[[18790.68963753]]\n",
      "    Current iteration=8000, loss=[[12628.8713437]]\n",
      "    Current iteration=9000, loss=[[6667.63347719]]\n",
      "    Current iteration=9999, loss=[[896.31916464]]\n",
      "    Current iteration=0, loss=[[53749.40496934]]\n",
      "    Current iteration=1000, loss=[[50381.32029742]]\n",
      "    Current iteration=2000, loss=[[47148.77699972]]\n",
      "    Current iteration=3000, loss=[[44041.91901654]]\n",
      "    Current iteration=4000, loss=[[41051.43513807]]\n",
      "    Current iteration=5000, loss=[[38168.69301343]]\n",
      "    Current iteration=6000, loss=[[35385.77209498]]\n",
      "    Current iteration=7000, loss=[[32695.44030696]]\n",
      "    Current iteration=8000, loss=[[30091.10566959]]\n",
      "    Current iteration=9000, loss=[[27566.76012447]]\n",
      "    Current iteration=9999, loss=[[25119.33807063]]\n",
      "    Current iteration=0, loss=[[34920.06180943]]\n",
      "    Current iteration=1000, loss=[[33393.04989845]]\n",
      "    Current iteration=2000, loss=[[31935.40326254]]\n",
      "    Current iteration=3000, loss=[[30542.79140984]]\n",
      "    Current iteration=4000, loss=[[29211.02300675]]\n",
      "    Current iteration=5000, loss=[[27936.08495687]]\n",
      "    Current iteration=6000, loss=[[26714.16870123]]\n",
      "    Current iteration=7000, loss=[[25541.68568581]]\n",
      "    Current iteration=8000, loss=[[24415.2740995]]\n",
      "    Current iteration=9000, loss=[[23331.7988943]]\n",
      "    Current iteration=9999, loss=[[22289.37124391]]\n",
      "    Current iteration=0, loss=[[15362.91410993]]\n",
      "    Current iteration=1000, loss=[[15073.11186361]]\n",
      "    Current iteration=2000, loss=[[14785.8075132]]\n",
      "    Current iteration=3000, loss=[[14500.97000613]]\n",
      "    Current iteration=4000, loss=[[14218.56826387]]\n",
      "    Current iteration=5000, loss=[[13938.57121266]]\n",
      "    Current iteration=6000, loss=[[13660.94781309]]\n",
      "    Current iteration=7000, loss=[[13385.66708815]]\n",
      "    Current iteration=8000, loss=[[13112.69814995]]\n",
      "    Current iteration=9000, loss=[[12842.01022503]]\n",
      "    Current iteration=9999, loss=[[12573.84000181]]\n"
     ]
    }
   ],
   "source": [
    "for group_idx in range(NUMBER_GROUPS):\n",
    "    polynom_degree = PARAM_arr[group_idx][DEGREE_IDX]\n",
    "    lambda_ = PARAM_arr[group_idx][LAMBDA_IDX]\n",
    "    tx = build_poly(TX_arr[group_idx], polynom_degree)# if polynom_degree > 1 else TX_arr[group_idx]\n",
    "    tx_test = build_poly(TX_test_arr[group_idx], polynom_degree)\n",
    "    initial_w = np.zeros((tx.shape[1], 1))\n",
    "    weight, loss = reg_logistic_regression(Y_arr[group_idx], tx, lambda_, initial_w, MAX_ITER, 0.00000000058)\n",
    "    y_pred[jet_groups_indices_test[group_idx]] = predict_labels(weight, tx_test).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating csv file\n",
    "OUTPUT_PATH = '../data/sample-submission_log_reg.csv'\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
