{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MACHINE LEARNING - PROJECT 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from proj1_helpers import *\n",
    "from implementations import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOAD THE TRAINING DATA INTO FEATURE MATRIX, CLASS LABELS and EVENT IDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.44 s, sys: 556 ms, total: 8.99 s\n",
      "Wall time: 9.15 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Load train data and supply path\n",
    "DATA_TRAIN_PATH = '../data/train.csv'\n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FEATURES ENGINEERING & DATA PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#constants definitions\n",
    "PRI_JET_NUM_IDX = 22   \n",
    "PRI_JET_NUM_VALUES = range(4)\n",
    "NUMBER_GROUPS = len(PRI_JET_NUM_VALUES)\n",
    "NBR_FEATURES = 30\n",
    "UNDEFINED_VALUE = -999.\n",
    "print_results = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seperating the data within the four groups\n",
    "jet_groups_indices = [tX[:, PRI_JET_NUM_IDX] == pri_jet_num_value for pri_jet_num_value in PRI_JET_NUM_VALUES]\n",
    "TX_arr = [tX[group_indices] for group_indices in jet_groups_indices]\n",
    "Y_arr, TX_arr = zip(*[(y[group_indices], tX[group_indices]) for group_indices in jet_groups_indices])\n",
    "Y_arr, TX_arr = list(Y_arr), list(TX_arr)\n",
    "\n",
    "#collecting the indices of the undefined features for each group\n",
    "undefined_features = [[], [], [], []]\n",
    "for group_idx in range(NUMBER_GROUPS):\n",
    "    tx = TX_arr[group_idx]\n",
    "    for feature_idx in range(NBR_FEATURES):\n",
    "        feature_column = tx[:, feature_idx]\n",
    "        if np.all(feature_column == UNDEFINED_VALUE):\n",
    "            undefined_features[group_idx].append(feature_idx)\n",
    "\n",
    "#computing the std of the features for each group\n",
    "STDS = [np.std(TX_arr[i], axis = 0) for i in range(NUMBER_GROUPS)]\n",
    "\n",
    "#collecting the indices of the features with no variance (i.e. constant features) within each groups\n",
    "cst_features = [[], [], [], []]\n",
    "for group_idx, elem in enumerate(STDS):\n",
    "    for feature_idx, std in enumerate(elem):\n",
    "        if std == 0. and feature_idx not in undefined_features[group_idx]:\n",
    "            cst_features[group_idx].append(feature_idx)\n",
    "\n",
    "#deleting the features either undefined or with no variance (i.e. constant features) within each groups\n",
    "features_to_keep = ([[x for x in range(NBR_FEATURES) \n",
    "                      if x not in undefined_features[group_idx] and x not in cst_features[group_idx]] \n",
    "                      for group_idx in range(NUMBER_GROUPS)])\n",
    "TX_arr = [TX_arr[group_idx][:, features_to_keep[group_idx]] for group_idx in range(NUMBER_GROUPS)]\n",
    "\n",
    "#standardizing the data\n",
    "for tx in TX_arr:\n",
    "    tx -= np.mean(tx, axis = 0)\n",
    "    tx /= np.std(tx, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features for group 0 :  18\n",
      "Number of features for group 1 :  22\n",
      "Number of features for group 2 :  29\n",
      "Number of features for group 3 :  29\n"
     ]
    }
   ],
   "source": [
    "# Print the remaining number of features for each JET NUMBER\n",
    "for i in PRI_JET_NUM_VALUES:\n",
    "    print(f\"Number of features for group {i} : \", len(features_to_keep[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21]\n",
      "[0, 1, 2, 3, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 29]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29]\n"
     ]
    }
   ],
   "source": [
    "print(features_to_keep[0])\n",
    "print(features_to_keep[1])\n",
    "print(features_to_keep[2])\n",
    "print(features_to_keep[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False ... False  True  True]\n",
      "[ 0.  0.  0. ...  0. -1. -1.]\n"
     ]
    }
   ],
   "source": [
    "print(jet_groups_indices[0])\n",
    "y_p = np.empty(250_000)\n",
    "y_p[jet_groups_indices[0]] = -1\n",
    "print(y_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Data with different models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LEAST SQUARES WITH GRADIENT DESCENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gamma = 0.01\n",
      "    For JET_NB 0, the obtained loss is 0.39229353135155837\n",
      "    For JET_NB 1, the obtained loss is 0.4132027466118129\n",
      "    For JET_NB 2, the obtained loss is 0.3551679496212518\n",
      "    For JET_NB 3, the obtained loss is 0.4356752189969854\n",
      "Gamma = 0.001\n",
      "    For JET_NB 0, the obtained loss is 0.4071890187854611\n",
      "    For JET_NB 1, the obtained loss is 0.42394948381609865\n",
      "    For JET_NB 2, the obtained loss is 0.3670042247722906\n",
      "    For JET_NB 3, the obtained loss is 0.44420031191889164\n",
      "Gamma = 0.0001\n",
      "    For JET_NB 0, the obtained loss is 0.4443662318323023\n",
      "    For JET_NB 1, the obtained loss is 0.4574097786010708\n",
      "    For JET_NB 2, the obtained loss is 0.41216640807377397\n",
      "    For JET_NB 3, the obtained loss is 0.4713233200193401\n",
      "Gamma = 1e-05\n",
      "    For JET_NB 0, the obtained loss is 0.49126372563414994\n",
      "    For JET_NB 1, the obtained loss is 0.4930816662458995\n",
      "    For JET_NB 2, the obtained loss is 0.48454918310149103\n",
      "    For JET_NB 3, the obtained loss is 0.49572853378650933\n",
      "CPU times: user 6min 29s, sys: 29.4 s, total: 6min 58s\n",
      "Wall time: 1min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "gammas = [0.01, 0.001, 0.0001, 0.00001]\n",
    "max_iters = 2000\n",
    "\n",
    "# Iterate over some gammas to find the best possible values\n",
    "for gamma in gammas:\n",
    "    print(f\"Gamma = {gamma}\")\n",
    "    \n",
    "    # Iterate over all jet numbers dataframes\n",
    "    for i in range(len(features_to_keep)):\n",
    "        initial_w = np.zeros(len(features_to_keep[i]))\n",
    "        y = Y_arr[i]\n",
    "        tx = TX_arr[i]\n",
    "        weights, loss = least_squares_GD(y, tx, initial_w, max_iters, gamma)\n",
    "        print(f\"    For JET_NB {i}, the obtained loss is {loss:>15}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LEAST SQUARES  WITH STOCHASTIC GRADIENT DESCENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gamma = 0.1\n",
      "    For JET_NB 0, the obtained loss is 1406874.6402069617\n",
      "    For JET_NB 1, the obtained loss is 8.905399313440892e+44\n",
      "    For JET_NB 2, the obtained loss is 2.62722134033137e+92\n",
      "    For JET_NB 3, the obtained loss is 3.6558229573636576e+99\n",
      "Gamma = 0.01\n",
      "    For JET_NB 0, the obtained loss is 0.46456667812924324\n",
      "    For JET_NB 1, the obtained loss is 0.48520943306089004\n",
      "    For JET_NB 2, the obtained loss is 0.40874983381282415\n",
      "    For JET_NB 3, the obtained loss is 0.5521115844435248\n",
      "Gamma = 0.001\n",
      "    For JET_NB 0, the obtained loss is 0.41290183723982854\n",
      "    For JET_NB 1, the obtained loss is 0.4297899798480046\n",
      "    For JET_NB 2, the obtained loss is 0.3730644250016471\n",
      "    For JET_NB 3, the obtained loss is 0.45520388622179947\n",
      "Gamma = 0.0001\n",
      "    For JET_NB 0, the obtained loss is 0.45264898655691643\n",
      "    For JET_NB 1, the obtained loss is 0.4645855495261453\n",
      "    For JET_NB 2, the obtained loss is 0.42308955262164477\n",
      "    For JET_NB 3, the obtained loss is 0.4773245748345276\n",
      "Gamma = 1e-05\n",
      "    For JET_NB 0, the obtained loss is 0.49344888278524623\n",
      "    For JET_NB 1, the obtained loss is 0.4949203144182571\n",
      "    For JET_NB 2, the obtained loss is 0.4880377631966352\n",
      "    For JET_NB 3, the obtained loss is 0.4969312480592395\n",
      "CPU times: user 6min 1s, sys: 21.6 s, total: 6min 23s\n",
      "Wall time: 6min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "gammas = [0.1, 0.01, 0.001, 0.0001, 0.00001]\n",
    "max_iters = 1500\n",
    "batch_size = 1\n",
    "\n",
    "# Iterate over some gammas to find the best possible values\n",
    "for gamma in gammas:\n",
    "    print(f\"Gamma = {gamma}\")\n",
    "    \n",
    "    # Iterate over all jet numbers dataframes\n",
    "    for i in range(len(features_to_keep)):\n",
    "        initial_w = np.zeros(len(features_to_keep[i]))\n",
    "        y = Y_arr[i]\n",
    "        tx = TX_arr[i]\n",
    "        weights, loss = least_squares_SGD(y, tx, initial_w, batch_size, max_iters, gamma)\n",
    "        print(f\"    For JET_NB {i}, the obtained loss is {loss:>15}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LEAST SQUARES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For JET_NB 0, the obtained loss is 0.3919078212020878\n",
      "For JET_NB 1, the obtained loss is 0.41308946507999145\n",
      "For JET_NB 2, the obtained loss is 0.3549970852299624\n",
      "For JET_NB 3, the obtained loss is 0.43547554636124286\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(features_to_keep)):\n",
    "    initial_w = np.zeros(len(features_to_keep[i]))\n",
    "    y = Y_arr[i]\n",
    "    tx = TX_arr[i]\n",
    "    weights, loss = least_squares(y, tx)\n",
    "    print(f\"For JET_NB {i}, the obtained loss is {loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RIDGE REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    min loss for a 2 polynomial expansion feature = 0.7578018775824853\n",
      "    min loss for a 3 polynomial expansion feature = 1.3711918852901765\n",
      "    min loss for a 4 polynomial expansion feature = 95.74535465786285\n",
      "For JET_NB 0, the obtained best degree is 2 and lambda is 0.14873521072935117\n",
      "    min loss for a 2 polynomial expansion feature = 0.8269923159385287\n",
      "    min loss for a 3 polynomial expansion feature = 0.8213430080153667\n",
      "    min loss for a 4 polynomial expansion feature = 0.826324413690626\n",
      "For JET_NB 1, the obtained best degree is 3 and lambda is 0.0001\n",
      "    min loss for a 2 polynomial expansion feature = 0.8077329060928659\n",
      "    min loss for a 3 polynomial expansion feature = 0.7977741061974317\n",
      "    min loss for a 4 polynomial expansion feature = 0.792004171469733\n",
      "For JET_NB 2, the obtained best degree is 4 and lambda is 0.01610262027560939\n",
      "    min loss for a 2 polynomial expansion feature = 0.8190071169100009\n",
      "    min loss for a 3 polynomial expansion feature = 0.8073636374533862\n",
      "    min loss for a 4 polynomial expansion feature = 0.8043028920252104\n",
      "For JET_NB 3, the obtained best degree is 4 and lambda is 0.0001\n",
      "CPU times: user 14min 46s, sys: 29.6 s, total: 15min 16s\n",
      "Wall time: 4min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "seed=15\n",
    "degrees=[2,3,4]\n",
    "k_fold=4\n",
    "lambdas = np.logspace(-4, 0, 30)\n",
    "\n",
    "for i in range(len(features_to_keep)):\n",
    "    y = Y_arr[i]\n",
    "    tx = TX_arr[i]\n",
    "    degree, lambda_ = cross_validation_demo_ridge(y, tx, seed, degrees, k_fold, lambdas)\n",
    "    print(f\"For JET_NB {i}, the obtained best degree is {degree} and lambda is {lambda_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "max_iters=10000\n",
    "gamma = 0.05\n",
    "\n",
    "for i in range(len(features_to_keep)):\n",
    "    y = Y_arr[i]\n",
    "    tx = TX_arr[i]\n",
    "    weights, loss = logistic_regression(y, tx, max_iters, gamma)\n",
    "    print(f\"For JET_NB {i}, the obtained loss is {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Current iteration=0, loss=51940.290828078825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/etiennebruno/Desktop/OneDrive - epfl.ch/ETIENNE/EPFL/EPFL_Master/MA1_EPFL/Machine_learning/ML_course_etienne/ml_project_1/scripts/implementations.py:38: RuntimeWarning: overflow encountered in exp\n",
      "  return 1.0 / (1 + np.exp(-t))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (74934,37) and (38,1) not aligned: 37 (dim 1) != 38 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/OneDrive - epfl.ch/ETIENNE/EPFL/EPFL_Master/MA1_EPFL/Machine_learning/ML_course_etienne/ml_project_1/scripts/implementations.py\u001b[0m in \u001b[0;36mcross_validation_demo_logistic\u001b[0;34m(y, x, max_iters, seed, degrees, k_fold, gammas)\u001b[0m\n\u001b[1;32m    213\u001b[0m             \u001b[0mrmse_te_tmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk_fold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m                 \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_te\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validation_logistic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdegree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m                 \u001b[0mrmse_te_tmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_te\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m             \u001b[0;31m#print(rmse_te_tmp)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/OneDrive - epfl.ch/ETIENNE/EPFL/EPFL_Master/MA1_EPFL/Machine_learning/ML_course_etienne/ml_project_1/scripts/implementations.py\u001b[0m in \u001b[0;36mcross_validation_logistic\u001b[0;34m(y, x, max_iters, k_indices, k, gamma, degree)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;31m# calculate the loss for train and test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m     \u001b[0mloss_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_rmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m     \u001b[0mloss_te\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_rmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_te\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx_te\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/OneDrive - epfl.ch/ETIENNE/EPFL/EPFL_Master/MA1_EPFL/Machine_learning/ML_course_etienne/ml_project_1/scripts/implementations.py\u001b[0m in \u001b[0;36mcompute_rmse\u001b[0;34m(y, tx, w)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompute_rmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;34m\"\"\"compute the loss by mse.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (74934,37) and (38,1) not aligned: 37 (dim 1) != 38 (dim 0)"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "max_iters=10000\n",
    "seed=15\n",
    "gamma = 0.05\n",
    "degrees=[2, 3, 4]\n",
    "k_fold=4\n",
    "gammas = [0.1, 0.01, 0.001, 0.0001]\n",
    "\n",
    "for i in range(len(features_to_keep)):\n",
    "    y = Y_arr[i]\n",
    "    tx = TX_arr[i]\n",
    "    degree, lambda_, rmse_min = cross_validation_demo_logistic(y, tx, max_iters, seed, degrees, k_fold, gammas)\n",
    "    print(f\"For JET_NB {i}, the obtained best degree is {degree} and lambda is {lambda_} and rsme is {rmse_min}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REGULARIZED LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "params = []\n",
    "\n",
    "for idx in range(4):\n",
    "    y=np.array(Y_arr[idx])\n",
    "    tX=np.array(TX_arr[idx])\n",
    "    initial_w = np.zeros(len(features_to_keep[idx]))\n",
    "    seed=15\n",
    "    degrees=[2, 4, 7]\n",
    "    k_fold=4\n",
    "    max_iters=200\n",
    "    lambdas = np.logspace(-4, 0, 10)\n",
    "    gammas = [0.01,0.001]\n",
    "    \n",
    "    tuple_ = cross_validation_demo_reg_logistic(y, tX, max_iters, seed, degrees, k_fold, lambdas, gammas)\n",
    "    params.append(tuple_)\n",
    "    print(\"group \",idx, \" tuple : \", tuple_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '../data/test.csv' # TODO: download test data and supply path here \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "jet_groups_indices_test = [tX_test[:, PRI_JET_NUM_IDX] == pri_jet_num_value for pri_jet_num_value in PRI_JET_NUM_VALUES]\n",
    "TX_test_arr = list([tX_test[group_indices] for group_indices in jet_groups_indices_test])\n",
    "\n",
    "#remove not used features\n",
    "TX_test_arr = [TX_test_arr[group_idx][:, features_to_keep[group_idx]] for group_idx in range(NUMBER_GROUPS)]\n",
    "\n",
    "#standardizing the data\n",
    "for tx in TX_test_arr:\n",
    "    tx -= np.mean(tx, axis = 0)\n",
    "    tx /= np.std(tx, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1. -1.  1. ...  1.  1. -1.]\n",
      "CPU times: user 8min 3s, sys: 28.7 s, total: 8min 32s\n",
      "Wall time: 2min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "W_arr = []\n",
    "y_pred = np.empty(len(tX_test))\n",
    "\n",
    "for idx in range(4):\n",
    "    #weight, loss = least_squares_GD(Y_arr[idx], TX_arr[idx], np.zeros(TX_arr[idx].shape[1]), 10000, 0.001)\n",
    "    #weight, loss = least_squares(Y_arr[idx], TX_arr[idx])\n",
    "    #weight, loss = ridge_regression(Y_arr[idx], TX_arr[idx], 0.01)\n",
    "    y_pred[jet_groups_indices_test[idx]] = predict_labels(weight, TX_test_arr[idx])\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: fill in desired name of output file for submission\n",
    "OUTPUT_PATH = '../data/sample-submission.csv'\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = np.array([1, 2, 3])\n",
    "l = np.array([True, False, True, False, False, True])\n",
    "A = np.zeros(6)\n",
    "A[l] = Q\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '../data/test.csv' # TODO: download test data and supply path here \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PREPARE TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jet_groups_indices = [tX_test[:, PRI_JET_NUM_IDX] == pri_jet_num_value for pri_jet_num_value in PRI_JET_NUM_VALUES]\n",
    "TX_test_arr = list([tX_test[group_indices] for group_indices in jet_groups_indices])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: fill in desired name of output file for submission\n",
    "OUTPUT_PATH = '../data/sample-submission.csv'\n",
    "y_pred = predict_labels(weights, tX_test)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
