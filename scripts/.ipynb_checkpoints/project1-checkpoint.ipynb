{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MACHINE LEARNING - PROJECT 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from proj1_helpers import *\n",
    "from implementations import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOAD THE TRAINING DATA INTO FEATURE MATRIX, CLASS LABELS and EVENT IDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.44 s, sys: 556 ms, total: 8.99 s\n",
      "Wall time: 9.15 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Load train data and supply path\n",
    "DATA_TRAIN_PATH = '../data/train.csv'\n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FEATURES ENGINEERING & DATA PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#constants definitions\n",
    "PRI_JET_NUM_IDX = 22   \n",
    "PRI_JET_NUM_VALUES = range(4)\n",
    "NUMBER_GROUPS = len(PRI_JET_NUM_VALUES)\n",
    "NBR_FEATURES = 30\n",
    "UNDEFINED_VALUE = -999.\n",
    "print_results = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seperating the data within the four groups\n",
    "jet_groups_indices = [tX[:, PRI_JET_NUM_IDX] == pri_jet_num_value for pri_jet_num_value in PRI_JET_NUM_VALUES]\n",
    "TX_arr = [tX[group_indices] for group_indices in jet_groups_indices]\n",
    "Y_arr, TX_arr = zip(*[(y[group_indices], tX[group_indices]) for group_indices in jet_groups_indices])\n",
    "Y_arr, TX_arr = list(Y_arr), list(TX_arr)\n",
    "\n",
    "#collecting the indices of the undefined features for each group\n",
    "undefined_features = [[], [], [], []]\n",
    "for group_idx in range(NUMBER_GROUPS):\n",
    "    tx = TX_arr[group_idx]\n",
    "    for feature_idx in range(NBR_FEATURES):\n",
    "        feature_column = tx[:, feature_idx]\n",
    "        if np.all(feature_column == UNDEFINED_VALUE):\n",
    "            undefined_features[group_idx].append(feature_idx)\n",
    "\n",
    "#computing the std of the features for each group\n",
    "STDS = [np.std(TX_arr[i], axis = 0) for i in range(NUMBER_GROUPS)]\n",
    "\n",
    "#collecting the indices of the features with no variance (i.e. constant features) within each groups\n",
    "cst_features = [[], [], [], []]\n",
    "for group_idx, elem in enumerate(STDS):\n",
    "    for feature_idx, std in enumerate(elem):\n",
    "        if std == 0. and feature_idx not in undefined_features[group_idx]:\n",
    "            cst_features[group_idx].append(feature_idx)\n",
    "\n",
    "#deleting the features either undefined or with no variance (i.e. constant features) within each groups\n",
    "features_to_keep = ([[x for x in range(NBR_FEATURES) \n",
    "                      if x not in undefined_features[group_idx] and x not in cst_features[group_idx]] \n",
    "                      for group_idx in range(NUMBER_GROUPS)])\n",
    "TX_arr = [TX_arr[group_idx][:, features_to_keep[group_idx]] for group_idx in range(NUMBER_GROUPS)]\n",
    "\n",
    "#standardizing the data\n",
    "for tx in TX_arr:\n",
    "    tx -= np.mean(tx, axis = 0)\n",
    "    tx /= np.std(tx, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features for group 0 :  18\n",
      "Number of features for group 1 :  22\n",
      "Number of features for group 2 :  29\n",
      "Number of features for group 3 :  29\n"
     ]
    }
   ],
   "source": [
    "# Print the remaining number of features for each JET NUMBER\n",
    "for i in PRI_JET_NUM_VALUES:\n",
    "    print(f\"Number of features for group {i} : \", len(features_to_keep[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21]\n",
      "[0, 1, 2, 3, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 29]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29]\n"
     ]
    }
   ],
   "source": [
    "print(features_to_keep[0])\n",
    "print(features_to_keep[1])\n",
    "print(features_to_keep[2])\n",
    "print(features_to_keep[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False ... False  True  True]\n",
      "[ 0.  0.  0. ...  0. -1. -1.]\n"
     ]
    }
   ],
   "source": [
    "print(jet_groups_indices[0])\n",
    "y_p = np.empty(250_000)\n",
    "y_p[jet_groups_indices[0]] = -1\n",
    "print(y_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Data with different models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LEAST SQUARES WITH GRADIENT DESCENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gamma = 0.01\n",
      "    For JET_NB 0, the obtained loss is 0.39229353135155837\n",
      "    For JET_NB 1, the obtained loss is 0.4132027466118129\n",
      "    For JET_NB 2, the obtained loss is 0.3551679496212518\n",
      "    For JET_NB 3, the obtained loss is 0.4356752189969854\n",
      "Gamma = 0.001\n",
      "    For JET_NB 0, the obtained loss is 0.4071890187854611\n",
      "    For JET_NB 1, the obtained loss is 0.42394948381609865\n",
      "    For JET_NB 2, the obtained loss is 0.3670042247722906\n",
      "    For JET_NB 3, the obtained loss is 0.44420031191889164\n",
      "Gamma = 0.0001\n",
      "    For JET_NB 0, the obtained loss is 0.4443662318323023\n",
      "    For JET_NB 1, the obtained loss is 0.4574097786010708\n",
      "    For JET_NB 2, the obtained loss is 0.41216640807377397\n",
      "    For JET_NB 3, the obtained loss is 0.4713233200193401\n",
      "Gamma = 1e-05\n",
      "    For JET_NB 0, the obtained loss is 0.49126372563414994\n",
      "    For JET_NB 1, the obtained loss is 0.4930816662458995\n",
      "    For JET_NB 2, the obtained loss is 0.48454918310149103\n",
      "    For JET_NB 3, the obtained loss is 0.49572853378650933\n",
      "CPU times: user 6min 29s, sys: 29.4 s, total: 6min 58s\n",
      "Wall time: 1min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "gammas = [0.01, 0.001, 0.0001, 0.00001]\n",
    "max_iters = 2000\n",
    "\n",
    "# Iterate over some gammas to find the best possible values\n",
    "for gamma in gammas:\n",
    "    print(f\"Gamma = {gamma}\")\n",
    "    \n",
    "    # Iterate over all jet numbers dataframes\n",
    "    for i in range(len(features_to_keep)):\n",
    "        initial_w = np.zeros(len(features_to_keep[i]))\n",
    "        y = Y_arr[i]\n",
    "        tx = TX_arr[i]\n",
    "        weights, loss = least_squares_GD(y, tx, initial_w, max_iters, gamma)\n",
    "        print(f\"    For JET_NB {i}, the obtained loss is {loss:>15}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LEAST SQUARES  WITH STOCHASTIC GRADIENT DESCENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gamma = 0.1\n",
      "    For JET_NB 0, the obtained loss is 1406874.6402069617\n",
      "    For JET_NB 1, the obtained loss is 8.905399313440892e+44\n",
      "    For JET_NB 2, the obtained loss is 2.62722134033137e+92\n",
      "    For JET_NB 3, the obtained loss is 3.6558229573636576e+99\n",
      "Gamma = 0.01\n",
      "    For JET_NB 0, the obtained loss is 0.46456667812924324\n",
      "    For JET_NB 1, the obtained loss is 0.48520943306089004\n",
      "    For JET_NB 2, the obtained loss is 0.40874983381282415\n",
      "    For JET_NB 3, the obtained loss is 0.5521115844435248\n",
      "Gamma = 0.001\n",
      "    For JET_NB 0, the obtained loss is 0.41290183723982854\n",
      "    For JET_NB 1, the obtained loss is 0.4297899798480046\n",
      "    For JET_NB 2, the obtained loss is 0.3730644250016471\n",
      "    For JET_NB 3, the obtained loss is 0.45520388622179947\n",
      "Gamma = 0.0001\n",
      "    For JET_NB 0, the obtained loss is 0.45264898655691643\n",
      "    For JET_NB 1, the obtained loss is 0.4645855495261453\n",
      "    For JET_NB 2, the obtained loss is 0.42308955262164477\n",
      "    For JET_NB 3, the obtained loss is 0.4773245748345276\n",
      "Gamma = 1e-05\n",
      "    For JET_NB 0, the obtained loss is 0.49344888278524623\n",
      "    For JET_NB 1, the obtained loss is 0.4949203144182571\n",
      "    For JET_NB 2, the obtained loss is 0.4880377631966352\n",
      "    For JET_NB 3, the obtained loss is 0.4969312480592395\n",
      "CPU times: user 6min 1s, sys: 21.6 s, total: 6min 23s\n",
      "Wall time: 6min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "gammas = [0.1, 0.01, 0.001, 0.0001, 0.00001]\n",
    "max_iters = 1500\n",
    "batch_size = 1\n",
    "\n",
    "# Iterate over some gammas to find the best possible values\n",
    "for gamma in gammas:\n",
    "    print(f\"Gamma = {gamma}\")\n",
    "    \n",
    "    # Iterate over all jet numbers dataframes\n",
    "    for i in range(len(features_to_keep)):\n",
    "        initial_w = np.zeros(len(features_to_keep[i]))\n",
    "        y = Y_arr[i]\n",
    "        tx = TX_arr[i]\n",
    "        weights, loss = least_squares_SGD(y, tx, initial_w, batch_size, max_iters, gamma)\n",
    "        print(f\"    For JET_NB {i}, the obtained loss is {loss:>15}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LEAST SQUARES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For JET_NB 0, the obtained loss is 0.3919078212020878\n",
      "For JET_NB 1, the obtained loss is 0.41308946507999145\n",
      "For JET_NB 2, the obtained loss is 0.3549970852299624\n",
      "For JET_NB 3, the obtained loss is 0.43547554636124286\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(features_to_keep)):\n",
    "    initial_w = np.zeros(len(features_to_keep[i]))\n",
    "    y = Y_arr[i]\n",
    "    tx = TX_arr[i]\n",
    "    weights, loss = least_squares(y, tx)\n",
    "    print(f\"For JET_NB {i}, the obtained loss is {loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RIDGE REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    min loss for a 2 polynomial expansion feature = 0.7578018775824853\n",
      "    min loss for a 3 polynomial expansion feature = 1.3711918852901765\n",
      "    min loss for a 4 polynomial expansion feature = 95.74535465786285\n",
      "For JET_NB 0, the obtained best degree is 2 and lambda is 0.14873521072935117\n",
      "    min loss for a 2 polynomial expansion feature = 0.8269923159385287\n",
      "    min loss for a 3 polynomial expansion feature = 0.8213430080153667\n",
      "    min loss for a 4 polynomial expansion feature = 0.826324413690626\n",
      "For JET_NB 1, the obtained best degree is 3 and lambda is 0.0001\n",
      "    min loss for a 2 polynomial expansion feature = 0.8077329060928659\n",
      "    min loss for a 3 polynomial expansion feature = 0.7977741061974317\n",
      "    min loss for a 4 polynomial expansion feature = 0.792004171469733\n",
      "For JET_NB 2, the obtained best degree is 4 and lambda is 0.01610262027560939\n",
      "    min loss for a 2 polynomial expansion feature = 0.8190071169100009\n",
      "    min loss for a 3 polynomial expansion feature = 0.8073636374533862\n",
      "    min loss for a 4 polynomial expansion feature = 0.8043028920252104\n",
      "For JET_NB 3, the obtained best degree is 4 and lambda is 0.0001\n",
      "CPU times: user 14min 46s, sys: 29.6 s, total: 15min 16s\n",
      "Wall time: 4min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "seed=15\n",
    "degrees=[2,3,4]\n",
    "k_fold=4\n",
    "lambdas = np.logspace(-4, 0, 30)\n",
    "\n",
    "for i in range(len(features_to_keep)):\n",
    "    y = Y_arr[i]\n",
    "    tx = TX_arr[i]\n",
    "    degree, lambda_ = cross_validation_demo_ridge(y, tx, seed, degrees, k_fold, lambdas)\n",
    "    print(f\"For JET_NB {i}, the obtained best degree is {degree} and lambda is {lambda_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=0, loss=69254.4142512852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/etiennebruno/Desktop/OneDrive - epfl.ch/ETIENNE/EPFL/EPFL_Master/MA1_EPFL/Machine_learning/ML_course_etienne/ml_project_1/scripts/implementations.py:38: RuntimeWarning: overflow encountered in exp\n",
      "  return 1.0 / (1 + np.exp(-t))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=100, loss=-2316152.9092520997\n",
      "Current iteration=200, loss=-2316079.9699931447\n",
      "Current iteration=300, loss=-2315768.160148527\n",
      "Current iteration=400, loss=-2316221.0033998964\n",
      "Current iteration=500, loss=-2315914.9561327803\n",
      "Current iteration=600, loss=-2315747.1542669297\n",
      "Current iteration=700, loss=-2315564.9906725064\n",
      "Current iteration=800, loss=-2316061.3120806003\n",
      "Current iteration=900, loss=-2316099.553082241\n",
      "Current iteration=1000, loss=-2316137.7940839026\n",
      "Current iteration=1100, loss=-2316176.035085573\n",
      "Current iteration=1200, loss=-2316214.2760872436\n",
      "Current iteration=1300, loss=-2316252.51708895\n",
      "Current iteration=1400, loss=-2316290.758090621\n",
      "Current iteration=1500, loss=-2316328.9990923163\n",
      "Current iteration=1600, loss=-2316367.2400940205\n",
      "Current iteration=1700, loss=-2316405.481095662\n",
      "Current iteration=1800, loss=-2316443.7220973787\n",
      "Current iteration=1900, loss=-2316481.963099038\n",
      "Current iteration=2000, loss=-2316520.2041007197\n",
      "Current iteration=2100, loss=-2316558.445102438\n",
      "Current iteration=2200, loss=-2316596.686104123\n",
      "Current iteration=2300, loss=-2316634.927105844\n",
      "Current iteration=2400, loss=-2316673.168107434\n",
      "Current iteration=2500, loss=-2316019.4046474397\n",
      "Current iteration=2600, loss=-2316019.4046475226\n",
      "Current iteration=2700, loss=-2316019.4046474393\n",
      "Current iteration=2800, loss=-2316019.404647462\n",
      "Current iteration=2900, loss=-2316019.404647444\n",
      "Current iteration=3000, loss=-2316019.404647391\n",
      "Current iteration=3100, loss=-2316019.404647471\n",
      "Current iteration=3200, loss=-2316019.404647483\n",
      "Current iteration=3300, loss=-2316019.404647502\n",
      "Current iteration=3400, loss=-2316019.404647417\n",
      "Current iteration=3500, loss=-2316019.4046474323\n",
      "Current iteration=3600, loss=-2316019.4046475\n",
      "Current iteration=3700, loss=-2316019.4046473554\n",
      "Current iteration=3800, loss=-2316019.4046474937\n",
      "Current iteration=3900, loss=-2316019.404647511\n",
      "Current iteration=4000, loss=-2316019.4046474854\n",
      "Current iteration=4100, loss=-2316019.404647479\n",
      "Current iteration=4200, loss=-2316019.404647526\n",
      "Current iteration=4300, loss=-2316019.404647396\n",
      "Current iteration=4400, loss=-2316019.4046474765\n",
      "Current iteration=4500, loss=-2316019.40464735\n",
      "Current iteration=4600, loss=-2316019.404647418\n",
      "Current iteration=4700, loss=-2316019.404647367\n",
      "Current iteration=4800, loss=-2316019.4046474714\n",
      "Current iteration=4900, loss=-2316019.40464736\n",
      "Current iteration=5000, loss=-2316019.4046473666\n",
      "Current iteration=5100, loss=-2316019.404647515\n",
      "Current iteration=5200, loss=-2316019.404647502\n",
      "Current iteration=5300, loss=-2316019.4046476036\n",
      "Current iteration=5400, loss=-2316019.4046475086\n",
      "Current iteration=5500, loss=-2316019.404647592\n",
      "Current iteration=5600, loss=-2316019.4046474285\n",
      "Current iteration=5700, loss=-2316019.4046473918\n",
      "Current iteration=5800, loss=-2316019.4046473727\n",
      "Current iteration=5900, loss=-2316019.4046474136\n",
      "Current iteration=6000, loss=-2316019.4046473275\n",
      "Current iteration=6100, loss=-2316019.4046474523\n",
      "Current iteration=6200, loss=-2316019.4046473783\n",
      "Current iteration=6300, loss=-2316019.404647377\n",
      "Current iteration=6400, loss=-2316019.4046475305\n",
      "Current iteration=6500, loss=-2316019.404647441\n",
      "Current iteration=6600, loss=-2316019.404647367\n",
      "Current iteration=6700, loss=-2316019.404647482\n",
      "Current iteration=6800, loss=-2316019.404647421\n",
      "Current iteration=6900, loss=-2316019.404647507\n",
      "Current iteration=7000, loss=-2316019.404647455\n",
      "Current iteration=7100, loss=-2316019.4046473796\n",
      "Current iteration=7200, loss=-2316019.404647371\n",
      "Current iteration=7300, loss=-2316019.404647464\n",
      "Current iteration=7400, loss=-2316019.4046474807\n",
      "Current iteration=7500, loss=-2316019.4046474826\n",
      "Current iteration=7600, loss=-2316019.4046474462\n",
      "Current iteration=7700, loss=-2316019.4046474216\n",
      "Current iteration=7800, loss=-2316019.4046473657\n",
      "Current iteration=7900, loss=-2316019.4046474476\n",
      "Current iteration=8000, loss=-2316019.404647367\n",
      "Current iteration=8100, loss=-2316019.4046474253\n",
      "Current iteration=8200, loss=-2316019.4046475696\n",
      "Current iteration=8300, loss=-2316019.4046473107\n",
      "Current iteration=8400, loss=-2316019.4046474644\n",
      "Current iteration=8500, loss=-2316019.404647329\n",
      "Current iteration=8600, loss=-2316019.4046474146\n",
      "Current iteration=8700, loss=-2316019.404647343\n",
      "Current iteration=8800, loss=-2316019.404647304\n",
      "Current iteration=8900, loss=-2316019.404647293\n",
      "Current iteration=9000, loss=-2316019.4046474276\n",
      "Current iteration=9100, loss=-2316019.4046471296\n",
      "Current iteration=9200, loss=-2316019.4046474556\n",
      "Current iteration=9300, loss=-2316019.4046476567\n",
      "Current iteration=9400, loss=-2316019.4046473578\n",
      "Current iteration=9500, loss=-2316019.4046473205\n",
      "Current iteration=9600, loss=-2316019.4046472865\n",
      "Current iteration=9700, loss=-2316019.4046473685\n",
      "Current iteration=9800, loss=-2316019.4046473927\n",
      "Current iteration=9900, loss=-2316019.4046473643\n",
      "loss=-2316019.4046474076\n",
      "-2316023.1285499074\n",
      "\n",
      "\n",
      "[[-3.14779239e+08]\n",
      " [ 7.13022713e+07]\n",
      " [-8.36062466e+07]\n",
      " [-1.13396027e+07]\n",
      " [ 2.19112677e+06]\n",
      " [ 5.67889244e+07]\n",
      " [ 2.19112625e+06]\n",
      " [ 1.70093313e+07]\n",
      " [-6.72982901e+07]\n",
      " [ 2.08453343e+07]\n",
      " [ 4.89845351e+07]\n",
      " [ 4.29156159e+05]\n",
      " [-1.33005516e+06]\n",
      " [-2.36702747e+07]\n",
      " [ 2.69473211e+06]\n",
      " [ 1.10717292e+06]\n",
      " [-6.10817886e+07]\n",
      " [-1.59031427e+06]\n",
      " [ 1.75936954e+07]]\n",
      "CPU times: user 4min 3s, sys: 5.04 s, total: 4min 8s\n",
      "Wall time: 1min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "max_iters=10000\n",
    "gamma = 0.5\n",
    "initial_w=np.ones(30)\n",
    "\n",
    "weights, loss = logistic_regression(Y_arr[0], TX_arr[0], max_iters, gamma)\n",
    "\n",
    "for i in range(len(features_to_keep)):\n",
    "    y = Y_arr[i]\n",
    "    tx = TX_arr[i]\n",
    "    weights, loss = logistic_regression(Y_arr[0], TX_arr[0], max_iters, gamma)\n",
    "    print(f\"For JET_NB {i}, the obtained loss is {loss}\")\n",
    "\n",
    "# TODO: fill in desired name of output file for submission\n",
    "#OUTPUT_PATH = '../data/sample-submission.csv'\n",
    "#y_pred = predict_labels(weights, tX_test)\n",
    "#create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(tX[0])\n",
    "#print(weights)\n",
    "y_pred = sigmoid(TX_arr[0] @ weights[1:19])\n",
    "y_pred[np.where(y_pred <= 0)] = -1\n",
    "y_pred[np.where(y_pred > 0)] = 1\n",
    "\n",
    "np.sum(y_pred == Y_arr[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_p = np.empty(250_000)\n",
    "y_pred = y_pred.flatten()\n",
    "y_p[jet_groups_indices[0]] = y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "4894204184 / Y_arr[0].shape[0]\n",
    "print(y_pred == Y_arr[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "params = []\n",
    "\n",
    "for idx in range(4):\n",
    "    y=np.array(Y_arr[idx])\n",
    "    tX=np.array(TX_arr[idx])\n",
    "    initial_w = np.zeros(len(features_to_keep[idx]))\n",
    "    seed=15\n",
    "    degrees=[2, 3, 4]\n",
    "    k_fold=4\n",
    "    max_iters=200\n",
    "    gammas = [0.01]\n",
    "    \n",
    "    tuple_ = cross_validation_demo_logistic(y, tX, max_iters, seed, degrees, k_fold, gammas)\n",
    "    params.append(tuple_)\n",
    "    print(\"group \",idx, \" tuple : \", tuple_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REGULARIZED LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "params = []\n",
    "\n",
    "for idx in range(4):\n",
    "    y=np.array(Y_arr[idx])\n",
    "    tX=np.array(TX_arr[idx])\n",
    "    initial_w = np.zeros(len(features_to_keep[idx]))\n",
    "    seed=15\n",
    "    degrees=[2, 4, 7]\n",
    "    k_fold=4\n",
    "    max_iters=200\n",
    "    lambdas = np.logspace(-4, 0, 10)\n",
    "    gammas = [0.01,0.001]\n",
    "    \n",
    "    tuple_ = cross_validation_demo_reg_logistic(y, tX, max_iters, seed, degrees, k_fold, lambdas, gammas)\n",
    "    params.append(tuple_)\n",
    "    print(\"group \",idx, \" tuple : \", tuple_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '../data/test.csv' # TODO: download test data and supply path here \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "jet_groups_indices_test = [tX_test[:, PRI_JET_NUM_IDX] == pri_jet_num_value for pri_jet_num_value in PRI_JET_NUM_VALUES]\n",
    "TX_test_arr = list([tX_test[group_indices] for group_indices in jet_groups_indices_test])\n",
    "\n",
    "#remove not used features\n",
    "TX_test_arr = [TX_test_arr[group_idx][:, features_to_keep[group_idx]] for group_idx in range(NUMBER_GROUPS)]\n",
    "\n",
    "#standardizing the data\n",
    "for tx in TX_test_arr:\n",
    "    tx -= np.mean(tx, axis = 0)\n",
    "    tx /= np.std(tx, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1. -1.  1. ...  1.  1. -1.]\n",
      "CPU times: user 8min 3s, sys: 28.7 s, total: 8min 32s\n",
      "Wall time: 2min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "W_arr = []\n",
    "y_pred = np.empty(len(tX_test))\n",
    "\n",
    "for idx in range(4):\n",
    "    #weight, loss = least_squares_GD(Y_arr[idx], TX_arr[idx], np.zeros(TX_arr[idx].shape[1]), 10000, 0.001)\n",
    "    #weight, loss = least_squares(Y_arr[idx], TX_arr[idx])\n",
    "    #weight, loss = ridge_regression(Y_arr[idx], TX_arr[idx], 0.01)\n",
    "    y_pred[jet_groups_indices_test[idx]] = predict_labels(weight, TX_test_arr[idx])\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: fill in desired name of output file for submission\n",
    "OUTPUT_PATH = '../data/sample-submission.csv'\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = np.array([1, 2, 3])\n",
    "l = np.array([True, False, True, False, False, True])\n",
    "A = np.zeros(6)\n",
    "A[l] = Q\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '../data/test.csv' # TODO: download test data and supply path here \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PREPARE TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jet_groups_indices = [tX_test[:, PRI_JET_NUM_IDX] == pri_jet_num_value for pri_jet_num_value in PRI_JET_NUM_VALUES]\n",
    "TX_test_arr = list([tX_test[group_indices] for group_indices in jet_groups_indices])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: fill in desired name of output file for submission\n",
    "OUTPUT_PATH = '../data/sample-submission.csv'\n",
    "y_pred = predict_labels(weights, tX_test)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
