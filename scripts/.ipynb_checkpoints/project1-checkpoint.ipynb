{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MACHINE LEARNING - PROJECT 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from proj1_helpers import *\n",
    "from implementations import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOAD THE TRAINING DATA INTO FEATURE MATRIX, CLASS LABELS and EVENT IDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.33 s, sys: 689 ms, total: 10 s\n",
      "Wall time: 10.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Load train data and supply path\n",
    "DATA_TRAIN_PATH = '../data/train.csv'\n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FEATURES ENGINEERING & DATA PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#constants definitions\n",
    "PRI_JET_NUM_IDX = 22   \n",
    "PRI_JET_NUM_VALUES = range(4)\n",
    "NUMBER_GROUPS = len(PRI_JET_NUM_VALUES)\n",
    "NBR_FEATURES = 30\n",
    "UNDEFINED_VALUE = -999.\n",
    "print_results = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "undefined values in dataset 0 ?  False\n",
      "undefined values in dataset 1 ?  False\n",
      "undefined values in dataset 2 ?  False\n",
      "undefined values in dataset 3 ?  False\n"
     ]
    }
   ],
   "source": [
    "#seperating the data within the four groups\n",
    "jet_groups_indices = [tX[:, PRI_JET_NUM_IDX] == pri_jet_num_value for pri_jet_num_value in PRI_JET_NUM_VALUES]\n",
    "TX_arr = [tX[group_indices] for group_indices in jet_groups_indices]\n",
    "Y_arr, TX_arr = zip(*[(y[group_indices], tX[group_indices]) for group_indices in jet_groups_indices])\n",
    "Y_arr, TX_arr = list(Y_arr), list(TX_arr)\n",
    "\n",
    "#collecting the indices of the undefined features for each group\n",
    "undefined_features = [[], [], [], []]\n",
    "for group_idx in range(NUMBER_GROUPS):\n",
    "    tx = TX_arr[group_idx]\n",
    "    for feature_idx in range(NBR_FEATURES):\n",
    "        feature_column = tx[:, feature_idx]\n",
    "        if np.all(feature_column == UNDEFINED_VALUE):\n",
    "            undefined_features[group_idx].append(feature_idx)\n",
    "\n",
    "#computing the std of the features for each group\n",
    "STDS = [np.std(TX_arr[i], axis = 0) for i in range(NUMBER_GROUPS)]\n",
    "\n",
    "#collecting the indices of the features with no variance (i.e. constant features) within each groups\n",
    "cst_features = [[], [], [], []]\n",
    "for group_idx, elem in enumerate(STDS):\n",
    "    for feature_idx, std in enumerate(elem):\n",
    "        if std == 0. and feature_idx not in undefined_features[group_idx]:\n",
    "            cst_features[group_idx].append(feature_idx)\n",
    "\n",
    "#deleting the features either undefined or with no variance (i.e. constant features) within each groups\n",
    "features_to_keep = ([[x for x in range(NBR_FEATURES) \n",
    "                      if x not in undefined_features[group_idx] and x not in cst_features[group_idx]] \n",
    "                      for group_idx in range(NUMBER_GROUPS)])\n",
    "TX_arr = [TX_arr[group_idx][:, features_to_keep[group_idx]] for group_idx in range(NUMBER_GROUPS)]\n",
    "\n",
    "# Store the computed medians of the training set\n",
    "# to be used in the data set when substituing UNDEFINED_VALUES\n",
    "train_medians = []\n",
    "for group_idx in range(NUMBER_GROUPS):\n",
    "    #computing median values for each column (excluding undefined values)\n",
    "    medians = np.apply_along_axis(lambda v: np.median(v[v!=UNDEFINED_VALUE]), 0, TX_arr[group_idx])\n",
    "    train_medians.append(medians)\n",
    "    #substituting median instead of undefined values\n",
    "    for col_num in range(TX_arr[group_idx].shape[1]):\n",
    "        column = TX_arr[group_idx][:, col_num]\n",
    "        column[column == UNDEFINED_VALUE] = medians[col_num]\n",
    "    print(f\"undefined values in dataset {group_idx} ? \", UNDEFINED_VALUE in TX_arr[group_idx])\n",
    "\n",
    "#standardizing the data\n",
    "#TX_arr = [standardize(TX_arr[idx]) for idx in range(NUMBER_GROUPS)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features for group 0 :  18\n",
      "Number of features for group 1 :  22\n",
      "Number of features for group 2 :  29\n",
      "Number of features for group 3 :  29\n"
     ]
    }
   ],
   "source": [
    "# Print the remaining number of features for each JET NUMBER\n",
    "for i in PRI_JET_NUM_VALUES:\n",
    "    print(f\"Number of features for group {i} : \", len(features_to_keep[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21]\n",
      "[0, 1, 2, 3, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 29]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29]\n"
     ]
    }
   ],
   "source": [
    "print(features_to_keep[0])\n",
    "print(features_to_keep[1])\n",
    "print(features_to_keep[2])\n",
    "print(features_to_keep[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Data with different models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LEAST SQUARES WITH GRADIENT DESCENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "gammas = [0.01, 0.001, 0.0001, 0.00001]\n",
    "max_iters = 2000\n",
    "\n",
    "# Iterate over some gammas to find the best possible values\n",
    "for gamma in gammas:\n",
    "    print(f\"Gamma = {gamma}\")\n",
    "    \n",
    "    # Iterate over all jet numbers dataframes\n",
    "    for i in range(len(features_to_keep)):\n",
    "        initial_w = np.zeros(len(features_to_keep[i]))\n",
    "        y = Y_arr[i]\n",
    "        tx = TX_arr[i]\n",
    "        weights, loss = least_squares_GD(y, tx, initial_w, max_iters, gamma)\n",
    "        print(f\"    For JET_NB {i}, the obtained loss is {loss:>15}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LEAST SQUARES  WITH STOCHASTIC GRADIENT DESCENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "gammas = [0.1, 0.01, 0.001, 0.0001, 0.00001]\n",
    "max_iters = 1500\n",
    "batch_size = 1\n",
    "\n",
    "# Iterate over some gammas to find the best possible values\n",
    "for gamma in gammas:\n",
    "    print(f\"Gamma = {gamma}\")\n",
    "    \n",
    "    # Iterate over all jet numbers dataframes\n",
    "    for i in range(len(features_to_keep)):\n",
    "        initial_w = np.zeros(len(features_to_keep[i]))\n",
    "        y = Y_arr[i]\n",
    "        tx = TX_arr[i]\n",
    "        weights, loss = least_squares_SGD(y, tx, initial_w, batch_size, max_iters, gamma)\n",
    "        print(f\"    For JET_NB {i}, the obtained loss is {loss:>15}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LEAST SQUARES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(features_to_keep)):\n",
    "    initial_w = np.zeros(len(features_to_keep[i]))\n",
    "    y = Y_arr[i]\n",
    "    tx = TX_arr[i]\n",
    "    weights, loss = least_squares(y, tx)\n",
    "    print(f\"For JET_NB {i}, the obtained loss is {loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RIDGE REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "seed=15\n",
    "degrees=[2,3,4]\n",
    "k_fold=4\n",
    "lambdas = np.logspace(-4, 0, 30)\n",
    "\n",
    "for i in range(len(features_to_keep)):\n",
    "    y = Y_arr[i]\n",
    "    tx = TX_arr[i]\n",
    "    degree, lambda_ = cross_validation_demo_ridge(y, tx, seed, degrees, k_fold, lambdas)\n",
    "    print(f\"For JET_NB {i}, the obtained best degree is {degree} and lambda is {lambda_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "max_iters = 5_000\n",
    "seed = 15\n",
    "degrees = [2, 3, 4, 6, 7]\n",
    "k_fold = 4\n",
    "gammas = [0.1, 0.01, 0.001]\n",
    "\n",
    "\n",
    "\n",
    "for i in range(NUMBER_GROUPS):\n",
    "    y = Y_arr[i]\n",
    "    y[y == - 1.0] = 0.0\n",
    "    tx = TX_arr[i]\n",
    "    degree, gamma, rmse_min = cross_validation_demo_logistic(y, tx, max_iters, seed, degrees, k_fold, gammas)\n",
    "    print(f\"For JET_NB {i}, the obtained best degree is {degree} and gamma is {gamma} and loss is {rmse_min}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REGULARIZED LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Current iteration=0, loss=[[51940.29082808]]\n",
      "    Current iteration=1000, loss=[[1511929.40313865]]\n",
      "    Current iteration=0, loss=[[51940.29082808]]\n",
      "    Current iteration=1000, loss=[[3654959.14855465]]\n",
      "    Current iteration=0, loss=[[51940.29082808]]\n",
      "    Current iteration=1000, loss=[[4322219.19095973]]\n",
      "    Current iteration=0, loss=[[51940.29082808]]\n",
      "    Current iteration=1000, loss=[[942249.14302433]]\n",
      "    Current iteration=0, loss=[[51940.29082808]]\n",
      "    Current iteration=1000, loss=[[735641.79405394]]\n",
      "    Current iteration=0, loss=[[51940.29082808]]\n",
      "    Current iteration=1000, loss=[[903182.79192065]]\n",
      "    Current iteration=0, loss=[[51940.29082808]]\n",
      "    Current iteration=1000, loss=[[897420.65745319]]\n",
      "    Current iteration=0, loss=[[51940.29082808]]\n",
      "    Current iteration=1000, loss=[[617667.6218758]]\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "seed=15\n",
    "degrees=[1, 2, 6]\n",
    "k_fold=4\n",
    "max_iters=2_000\n",
    "lambdas = [0.01,0.001]\n",
    "gammas = np.logspace(-6, -2, 3)\n",
    "    \n",
    "params = []\n",
    "\n",
    "for idx in range(4):\n",
    "    y=np.array(Y_arr[idx])\n",
    "    y[y == - 1.0] = 0.0\n",
    "    tX=np.array(TX_arr[idx])\n",
    "    initial_w = np.zeros(len(features_to_keep[idx]))\n",
    "    tuple_ = cross_validation_demo_reg_logistic(y, tX, max_iters, seed, degrees, k_fold, lambdas, gammas)\n",
    "    params.append(tuple_)\n",
    "    print(\"group \",idx, \" tuple : \", tuple_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_csv_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-8a27fa951a51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mDATA_TRAIN_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../data/train.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_csv_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_TRAIN_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnbr_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnbr_samples_with_undefined_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_csv_data' is not defined"
     ]
    }
   ],
   "source": [
    "DATA_TRAIN_PATH = '../data/train.csv'\n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)\n",
    "\n",
    "nbr_samples = tX.shape[0]\n",
    "nbr_samples_with_undefined_features = 0\n",
    "nbr_undefined_features = 0\n",
    "nbr_features = tX.shape[0] * tX.shape[1]\n",
    "\n",
    "for line_idx in range(tX.shape[0]):\n",
    "    contains_undefined_feature = False\n",
    "    for column_idx in range(len(tX[line_idx])):\n",
    "        if tX[line_idx][column_idx] == UNDEFINED_VALUE:\n",
    "            contains_undefined_feature = True\n",
    "            nbr_undefined_features += 1\n",
    "    if contains_undefined_feature:\n",
    "          nbr_samples_with_undefined_features += 1\n",
    "\n",
    "print(f\"total number of samples : {nbr_samples}\")\n",
    "print(f\"number of samples with undefined features : {nbr_samples_with_undefined_features}\")\n",
    "print(f\"proportion of samples with undefined features : {nbr_samples_with_undefined_features / nbr_samples}\")\n",
    "\n",
    "print(f\"\\ntotal number of features : {nbr_features}\")\n",
    "print(f\"total number undefined features : {nbr_undefined_features}\")\n",
    "print(f\"proportion of undefined features : {nbr_undefined_features / nbr_features }\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
